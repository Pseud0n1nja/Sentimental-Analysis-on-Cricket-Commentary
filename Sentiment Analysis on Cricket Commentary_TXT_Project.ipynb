{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:59:37.268216Z",
     "start_time": "2020-04-08T13:59:36.569596Z"
    }
   },
   "source": [
    "### Authors : Kedarkumar Golla, Krishnan Hariharan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  SENTIMENT ANAYLSIS ON CRICKET COMMENTARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE\n",
    "\n",
    "Measuring the performance of a cricket player using only statistical analysis will not completely describe how well or how bad he performed ball-by-ball. The objective of this project is to measure the performance of a player (batsman) using Sentiment Analysis on ball-by-ball cricket commentary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import text \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline \n",
    "import nltk\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DATA AFTER WEB SCRAPING AND LABELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:59:38.456548Z",
     "start_time": "2020-04-08T13:59:37.764273Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the web scraped and labelled data\n",
    "\n",
    "data=pd.read_excel(r\"C:\\Users\\KRISH\\Desktop\\TXT\\All_Matches.xlsx\")\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PRE-PROCESSING THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:59:39.026467Z",
     "start_time": "2020-04-08T13:59:38.869509Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating Class based on the sentiment\n",
    "\n",
    "data.loc[data[\"Sentiment\"]==\"negative\",\"Class\"]=0\n",
    "data.loc[data[\"Sentiment\"]==\"positive\",\"Class\"]=1\n",
    "data[\"Class\"]=data[\"Class\"].astype(\"int\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:59:43.671078Z",
     "start_time": "2020-04-08T13:59:43.664082Z"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[data[\"Runs\"]==\"W\",\"Runs\"]=9\n",
    "\n",
    "def stringToNumbers(Runs):\n",
    "    if str(Runs).isdigit():\n",
    "        return Runs\n",
    "    else:\n",
    "        for i in Runs:\n",
    "            if i.isdigit():\n",
    "                return int(i)\n",
    "\n",
    "data[\"Runs\"]=data[\"Runs\"].apply(lambda x:stringToNumbers(x))\n",
    "data.loc[data[\"Runs\"]==9,\"Runs\"]=-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:59:46.092884Z",
     "start_time": "2020-04-08T13:59:46.085887Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_excel(\"Full_data_Preprocessed_pandas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:59:46.694471Z",
     "start_time": "2020-04-08T13:59:46.685496Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Class\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:12.109637Z",
     "start_time": "2020-04-08T14:00:12.096644Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:14.534251Z",
     "start_time": "2020-04-08T14:00:13.217005Z"
    }
   },
   "source": [
    "### 3. PRE-PROCESSING THE COMMENTARY TEXTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Removing Names from the commentaries using POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:19.667320Z",
     "start_time": "2020-04-08T14:00:14.660180Z"
    }
   },
   "outputs": [],
   "source": [
    "def removing_names(sentence):\n",
    "    tagged_sentence = nltk.tag.pos_tag(sentence.split())\n",
    "    edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "    edited_sentence = ' '.join(word for word in edited_sentence)\n",
    "    return edited_sentence\n",
    "\n",
    "data[\"edited_Commentry\"]=data[\"Commentary\"].apply(lambda x:removing_names(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Creating problem sepcific Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:21.651746Z",
     "start_time": "2020-04-08T14:00:21.366066Z"
    }
   },
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english')\n",
    "\n",
    "important_list=['do', 'does', 'did', 'doing','above', 'below', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then','once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very','can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "for i in important_list:\n",
    "    all_stopwords.remove(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:25.732274Z",
     "start_time": "2020-04-08T14:00:25.525393Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize using Count Vectorizer with Unigrams (n-gram size = 1)\n",
    "\n",
    "count_vec_unigram = CountVectorizer(binary=True, stop_words=all_stopwords, ngram_range=(1,1),lowercase=False,min_df=0.01)\n",
    "count_vec_unigram.fit(data.edited_Commentry)\n",
    "small_transformed_new = count_vec_unigram.transform(data.edited_Commentry)\n",
    "print(DataFrame(small_transformed_new.A, columns=count_vec_unigram.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize using Count Vectorizer with Bigrams (n-gram size = 2)\n",
    "\n",
    "count_vec_bigram = CountVectorizer(binary=True, stop_words=all_stopwords, ngram_range=(2,2),lowercase=False,min_df=0.01)\n",
    "count_vec_bigram.fit(data.edited_Commentry)\n",
    "small_transformed_new = count_vec_bigram.transform(data.edited_Commentry)\n",
    "print(DataFrame(small_transformed_new.A, columns=count_vec_bigram.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:28.393753Z",
     "start_time": "2020-04-08T14:00:27.994982Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize using Count Vectorizer with both Unigrams (n-gram size = 1)and Bigrams (n-gram size = 2)\n",
    "\n",
    "count_vec_bigram = CountVectorizer(binary=True, stop_words=all_stopwords, ngram_range=(1,2),lowercase=False,min_df=0.01)\n",
    "count_vec_bigram.fit(data.edited_Commentry)\n",
    "small_transformed_new = count_vec_bigram.transform(data.edited_Commentry)\n",
    "print(DataFrame(small_transformed_new.A, columns=count_vec_bigram.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:31.394062Z",
     "start_time": "2020-04-08T14:00:28.998408Z"
    }
   },
   "source": [
    "#### d) Calculating TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:31.586239Z",
     "start_time": "2020-04-08T14:00:31.398038Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=True)\n",
    "tfidf.fit(small_transformed_new)\n",
    "small_tfidfed = tfidf.transform(small_transformed_new)\n",
    "print(DataFrame(small_tfidfed.A, columns=count_vec_bigram.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MODEL BUILDING FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:34.899170Z",
     "start_time": "2020-04-08T14:00:31.588201Z"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:34.911163Z",
     "start_time": "2020-04-08T14:00:34.905165Z"
    }
   },
   "outputs": [],
   "source": [
    "#Logstic Regression Model\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=.8, random_state=21,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:36.063403Z",
     "start_time": "2020-04-08T14:00:36.059404Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the Pipeline\n",
    "\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True, stop_words=all_stopwords, ngram_range=(1,2),lowercase=False,min_df=0.01)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', lr),\n",
    "#     ('clf', SGDClassifier()), #by default, this is SVM\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:37.485589Z",
     "start_time": "2020-04-08T14:00:37.464602Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:38.558977Z",
     "start_time": "2020-04-08T14:00:38.547982Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train-Test-Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     data.edited_Commentry, data.Class, test_size=0.35, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:41.220186Z",
     "start_time": "2020-04-08T14:00:40.793426Z"
    }
   },
   "outputs": [],
   "source": [
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:42.399510Z",
     "start_time": "2020-04-08T14:00:42.389516Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_test[0:4])\n",
    "print(y_test[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:44.352761Z",
     "start_time": "2020-04-08T14:00:44.341768Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop = True) # drop=True discards the old index\n",
    "X_test[0:4]\n",
    "\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "y_test[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:48.339048Z",
     "start_time": "2020-04-08T14:00:48.106867Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_test = text_classifier.predict(X_test)\n",
    "predicted_proba_test = text_classifier.predict_proba(X_test)\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"{}, {}, {}, {}\".format(X_test[i], predicted_test[i], predicted_proba_test[i], y_test[i]))\n",
    "    print(predicted_proba_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) F1 SCORE and CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:49.762205Z",
     "start_time": "2020-04-08T14:00:49.575291Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_train = text_classifier.predict(X_train)\n",
    "\n",
    "y_train = y_train.astype('category')\n",
    "print(metrics.classification_report(y_train, predicted_train,\n",
    "    labels=y_train.cat.categories.tolist()))\n",
    "\n",
    "print(metrics.confusion_matrix(y_train, predicted_train))\n",
    "\n",
    "predicted_test = text_classifier.predict(X_test)\n",
    "\n",
    "y_test = y_test.astype('category')\n",
    "print(metrics.classification_report(y_test, predicted_test,\n",
    "    labels=y_test.cat.categories.tolist()))\n",
    "\n",
    "metrics.confusion_matrix(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:50.876165Z",
     "start_time": "2020-04-08T14:00:50.853176Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, predicted_test, average='macro') \n",
    "metrics.precision_score(y_test, predicted_test, average='micro') \n",
    "metrics.precision_score(y_test, predicted_test, average='weighted') \n",
    "metrics.recall_score(y_test, predicted_test, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) ROC Curve (No-Skill Prediction Vs Logistic Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:54.825165Z",
     "start_time": "2020-04-08T14:00:54.792184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a No skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "#Predict probabilities\n",
    "lr_probs = pd.DataFrame(text_classifier.predict_proba(X_test),columns={0,1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:00:56.105312Z",
     "start_time": "2020-04-08T14:00:55.826452Z"
    }
   },
   "outputs": [],
   "source": [
    "#Keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs.iloc[:, 1]\n",
    "\n",
    "#Calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "#Summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "#Calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "#Plot the roc curve for the model\n",
    "\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "\n",
    "#Axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "\n",
    "#Show the legend\n",
    "pyplot.legend()\n",
    "\n",
    "#Show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PLAYER COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is the best opener for Indian team for home matches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KL RAHUL vs ROHIT SHARMA vs SHIKHAR DHAWAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T18:03:39.640929Z",
     "start_time": "2020-04-08T18:03:39.621938Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the whole pipeline\n",
    "\n",
    "def preprocess(filename,sheetname):\n",
    "    data=pd.read_excel(filename,sheet_name=sheetname)\n",
    "    data[\"edited_Commentry\"]=data[\"Commentary\"].apply(lambda x:removing_names(x))\n",
    "    all_stopwords = stopwords.words('english')\n",
    "\n",
    "    important_list=['do', 'does', 'did', 'doing','above', 'below', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then','once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very','can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "    for i in important_list:\n",
    "        all_stopwords.remove(i)\n",
    "    predicted_test = text_classifier.predict(data.edited_Commentry)\n",
    "    predicted_proba_test = text_classifier.predict_proba(data.edited_Commentry)\n",
    "    \n",
    "    \n",
    "    input_data={\"edited_Commentry\":data.edited_Commentry,\"predicted_class\":predicted_test}\n",
    "    final_df=pd.DataFrame(input_data)\n",
    "    #return len(data.edited_Commentry),len(predicted_test),len(predicted_proba_test)\n",
    "    counts=final_df[\"predicted_class\"].value_counts()\n",
    "    \n",
    "    \n",
    "    #Create a comparison metric (Sentiment Score) for comparison of both the players\n",
    "    \n",
    "    positive_decisions=counts[1]\n",
    "    negitive_decisions=counts[0]\n",
    "    total_balls=positive_decisions+negitive_decisions\n",
    "    sentiment_score_for_the_match=(positive_decisions/negitive_decisions)*total_balls\n",
    "    return round(sentiment_score_for_the_match,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL RAHUL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSING PERFORMANCE OF KL RAHUL IN LAST 5 INNINGS IN INDIA AS OPENER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rahul_score_RR1=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR1RA\")\n",
    "Rahul_score_RR2=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR2RA\")\n",
    "Rahul_score_RR3=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR3RA\")\n",
    "Rahul_score_RR4=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR4RA\")\n",
    "Rahul_score_RR5=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR5RA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentimental Score of KL RAHUL in the last 5 Innings he played in India as Opener\n",
    "\n",
    "Rahul_scores=[Rahul_score_RR1,Rahul_score_RR2,Rahul_score_RR3,Rahul_score_RR4,Rahul_score_RR5]\n",
    "print(\"KL Rahul Scores in the last 5 innings in India  :\\n\\n\",Rahul_scores)\n",
    "Rahul_mean_score=round(np.mean(Rahul_scores),2)\n",
    "print(\"\\nMean : \",Rahul_mean_score)\n",
    "Rahul_median_score=np.median(Rahul_scores)\n",
    "print(\"Median : \",Rahul_median_score)\n",
    "std_Rahul_score=round(np.std(Rahul_scores),2)\n",
    "print(\"Standard Deviation : \",std_Rahul_score)\n",
    "print(\"Coefficient of Variation : \",std_Rahul_score/Rahul_mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROHIT SHARMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSING PERFORMANCE OF ROHIT SHARMA IN LAST 5 INNINGS IN INDIA AS OPENER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T18:03:41.985738Z",
     "start_time": "2020-04-08T18:03:41.573935Z"
    }
   },
   "outputs": [],
   "source": [
    "rohit_score_RR1=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR1RS\")\n",
    "rohit_score_RS2=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"RohitRsd2\")\n",
    "rohit_score_RS1=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"RohitRSD1\")\n",
    "rohit_score_RR4=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR4RS\")\n",
    "rohit_score_RR3=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RR_ALL.xlsx\",\"RR3RS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T18:38:12.540548Z",
     "start_time": "2020-04-08T18:38:12.530555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sentimental Score of ROHIT SHARMA in the last 5 Innings he played in India as Opener\n",
    "\n",
    "Rohit_scores=[rohit_score_RR1,rohit_score_RS2,rohit_score_RS1,rohit_score_RR4,rohit_score_RR3]\n",
    "print(\"Rohit Sharma Scores in the last 5 innings in India  :\\n\\n \",Rohit_scores)\n",
    "Rohit_mean_score=round(np.mean(Rohit_scores),2)\n",
    "print(\"\\nMean : \",Rohit_mean_score)\n",
    "Rohit_median_score=np.median(Rohit_scores)\n",
    "print(\"Median : \",Rohit_median_score)\n",
    "std_Rohit_score=round(np.std(Rohit_scores),2)\n",
    "print(\"Standard Deviation : \",std_Rohit_score)\n",
    "print(\"Coefficient of Variation: \",round((std_Rohit_score/Rohit_mean_score),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHIKHAR DHAWAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ANALYSING PERFORMANCE OF SHIKHAR DHWAN IN LAST 5 INNINGS IN INDIA AS OPENER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shikar_score_RS1=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"ShikarRsd1\")\n",
    "Shikar_score_RS2=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"ShikarRSD2\")\n",
    "Shikar_score_RS3=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"SikharRSD3\")\n",
    "Shikar_score_RS4=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"SIkharRSD4\")\n",
    "Shikar_score_RS5=preprocess(r\"C:\\Users\\KRISH\\Desktop\\TXT\\RS_ALL.xlsx\",\"ShikarRSD5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentimental Score of SHIKHAR DHAWAN in the last 5 Innings he played in India as Opener\n",
    "\n",
    "Shikar_scores=[Shikar_score_RS1,Shikar_score_RS2,Shikar_score_RS3,Shikar_score_RS4,Shikar_score_RS5]\n",
    "print(\"Shikhar Dhawan Scores in the last 5 innings in India  :\\n\\n\",Shikar_scores)\n",
    "Shikar_mean_score=round(np.mean(Shikar_scores),2)\n",
    "print(\"\\nMean : \",Shikar_mean_score)\n",
    "Shikar_median_score=np.median(Shikar_scores)\n",
    "print(\"Median : \",Shikar_median_score)\n",
    "std_Shikar_score=round(np.std(Shikar_scores),2)\n",
    "print(\"Standard Deviation : \",std_Shikar_score)\n",
    "print(\"Coefficient of Variation : \",std_Shikar_score/Shikar_mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T18:03:59.862532Z",
     "start_time": "2020-04-08T18:03:59.499743Z"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Variation of Sentiment  scores of players :\n",
    " \n",
    "### KL RAHUL\t\t\t \t         : \t\t   1.06\n",
    "### SHIKHAR DHAWAN\t\t    : \t\t  0.74\n",
    "### ROHIT SHARMA\t\t\t   :\t\t  0.63\n",
    "\n",
    "### By comparing the Coefficient of variation of Sentiment  scores of the players, we can infer that ROHIT SHARMA is the best opener among the three and SHIKHAR DHAWAN is a better opener than KL RAHUL for Indian team to play ODI matches in India.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
